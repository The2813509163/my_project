08/16 11:52:50 - OpenCompass - INFO - Task [Llama-3.2-3B_hf/lambada_6]
08/16 11:52:52 - OpenCompass - WARNING - pad_token_id is not set for the tokenizer.
08/16 11:52:52 - OpenCompass - WARNING - Using eos_token_id 128001 as pad_token_id.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.75it/s]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /data/kris/shared_data/models/Llama-3.2-3B and are newly initialized: ['model.HIO_A_Emb', 'model.HIO_B_Emb', 'model.HSM_mask_proxy', 'model.layers.0.HIO_A_Attn', 'model.layers.0.HIO_A_MLP', 'model.layers.0.HIO_B_Attn', 'model.layers.0.HIO_B_MLP', 'model.layers.0.mlp.HIO_A_down_proj', 'model.layers.0.mlp.HIO_B_down_proj', 'model.layers.0.mlp.HSM_mask_proxy', 'model.layers.1.HIO_A_Attn', 'model.layers.1.HIO_A_MLP', 'model.layers.1.HIO_B_Attn', 'model.layers.1.HIO_B_MLP', 'model.layers.1.mlp.HIO_A_down_proj', 'model.layers.1.mlp.HIO_B_down_proj', 'model.layers.1.mlp.HSM_mask_proxy', 'model.layers.10.HIO_A_Attn', 'model.layers.10.HIO_A_MLP', 'model.layers.10.HIO_B_Attn', 'model.layers.10.HIO_B_MLP', 'model.layers.10.mlp.HIO_A_down_proj', 'model.layers.10.mlp.HIO_B_down_proj', 'model.layers.10.mlp.HSM_mask_proxy', 'model.layers.11.HIO_A_Attn', 'model.layers.11.HIO_A_MLP', 'model.layers.11.HIO_B_Attn', 'model.layers.11.HIO_B_MLP', 'model.layers.11.mlp.HIO_A_down_proj', 'model.layers.11.mlp.HIO_B_down_proj', 'model.layers.11.mlp.HSM_mask_proxy', 'model.layers.12.HIO_A_Attn', 'model.layers.12.HIO_A_MLP', 'model.layers.12.HIO_B_Attn', 'model.layers.12.HIO_B_MLP', 'model.layers.12.mlp.HIO_A_down_proj', 'model.layers.12.mlp.HIO_B_down_proj', 'model.layers.12.mlp.HSM_mask_proxy', 'model.layers.13.HIO_A_Attn', 'model.layers.13.HIO_A_MLP', 'model.layers.13.HIO_B_Attn', 'model.layers.13.HIO_B_MLP', 'model.layers.13.mlp.HIO_A_down_proj', 'model.layers.13.mlp.HIO_B_down_proj', 'model.layers.13.mlp.HSM_mask_proxy', 'model.layers.14.HIO_A_Attn', 'model.layers.14.HIO_A_MLP', 'model.layers.14.HIO_B_Attn', 'model.layers.14.HIO_B_MLP', 'model.layers.14.mlp.HIO_A_down_proj', 'model.layers.14.mlp.HIO_B_down_proj', 'model.layers.14.mlp.HSM_mask_proxy', 'model.layers.15.HIO_A_Attn', 'model.layers.15.HIO_A_MLP', 'model.layers.15.HIO_B_Attn', 'model.layers.15.HIO_B_MLP', 'model.layers.15.mlp.HIO_A_down_proj', 'model.layers.15.mlp.HIO_B_down_proj', 'model.layers.15.mlp.HSM_mask_proxy', 'model.layers.16.HIO_A_Attn', 'model.layers.16.HIO_A_MLP', 'model.layers.16.HIO_B_Attn', 'model.layers.16.HIO_B_MLP', 'model.layers.16.mlp.HIO_A_down_proj', 'model.layers.16.mlp.HIO_B_down_proj', 'model.layers.16.mlp.HSM_mask_proxy', 'model.layers.17.HIO_A_Attn', 'model.layers.17.HIO_A_MLP', 'model.layers.17.HIO_B_Attn', 'model.layers.17.HIO_B_MLP', 'model.layers.17.mlp.HIO_A_down_proj', 'model.layers.17.mlp.HIO_B_down_proj', 'model.layers.17.mlp.HSM_mask_proxy', 'model.layers.18.HIO_A_Attn', 'model.layers.18.HIO_A_MLP', 'model.layers.18.HIO_B_Attn', 'model.layers.18.HIO_B_MLP', 'model.layers.18.mlp.HIO_A_down_proj', 'model.layers.18.mlp.HIO_B_down_proj', 'model.layers.18.mlp.HSM_mask_proxy', 'model.layers.19.HIO_A_Attn', 'model.layers.19.HIO_A_MLP', 'model.layers.19.HIO_B_Attn', 'model.layers.19.HIO_B_MLP', 'model.layers.19.mlp.HIO_A_down_proj', 'model.layers.19.mlp.HIO_B_down_proj', 'model.layers.19.mlp.HSM_mask_proxy', 'model.layers.2.HIO_A_Attn', 'model.layers.2.HIO_A_MLP', 'model.layers.2.HIO_B_Attn', 'model.layers.2.HIO_B_MLP', 'model.layers.2.mlp.HIO_A_down_proj', 'model.layers.2.mlp.HIO_B_down_proj', 'model.layers.2.mlp.HSM_mask_proxy', 'model.layers.20.HIO_A_Attn', 'model.layers.20.HIO_A_MLP', 'model.layers.20.HIO_B_Attn', 'model.layers.20.HIO_B_MLP', 'model.layers.20.mlp.HIO_A_down_proj', 'model.layers.20.mlp.HIO_B_down_proj', 'model.layers.20.mlp.HSM_mask_proxy', 'model.layers.21.HIO_A_Attn', 'model.layers.21.HIO_A_MLP', 'model.layers.21.HIO_B_Attn', 'model.layers.21.HIO_B_MLP', 'model.layers.21.mlp.HIO_A_down_proj', 'model.layers.21.mlp.HIO_B_down_proj', 'model.layers.21.mlp.HSM_mask_proxy', 'model.layers.22.HIO_A_Attn', 'model.layers.22.HIO_A_MLP', 'model.layers.22.HIO_B_Attn', 'model.layers.22.HIO_B_MLP', 'model.layers.22.mlp.HIO_A_down_proj', 'model.layers.22.mlp.HIO_B_down_proj', 'model.layers.22.mlp.HSM_mask_proxy', 'model.layers.23.HIO_A_Attn', 'model.layers.23.HIO_A_MLP', 'model.layers.23.HIO_B_Attn', 'model.layers.23.HIO_B_MLP', 'model.layers.23.mlp.HIO_A_down_proj', 'model.layers.23.mlp.HIO_B_down_proj', 'model.layers.23.mlp.HSM_mask_proxy', 'model.layers.24.HIO_A_Attn', 'model.layers.24.HIO_A_MLP', 'model.layers.24.HIO_B_Attn', 'model.layers.24.HIO_B_MLP', 'model.layers.24.mlp.HIO_A_down_proj', 'model.layers.24.mlp.HIO_B_down_proj', 'model.layers.24.mlp.HSM_mask_proxy', 'model.layers.25.HIO_A_Attn', 'model.layers.25.HIO_A_MLP', 'model.layers.25.HIO_B_Attn', 'model.layers.25.HIO_B_MLP', 'model.layers.25.mlp.HIO_A_down_proj', 'model.layers.25.mlp.HIO_B_down_proj', 'model.layers.25.mlp.HSM_mask_proxy', 'model.layers.26.HIO_A_Attn', 'model.layers.26.HIO_A_MLP', 'model.layers.26.HIO_B_Attn', 'model.layers.26.HIO_B_MLP', 'model.layers.26.mlp.HIO_A_down_proj', 'model.layers.26.mlp.HIO_B_down_proj', 'model.layers.26.mlp.HSM_mask_proxy', 'model.layers.27.HIO_A_Attn', 'model.layers.27.HIO_A_MLP', 'model.layers.27.HIO_B_Attn', 'model.layers.27.HIO_B_MLP', 'model.layers.27.mlp.HIO_A_down_proj', 'model.layers.27.mlp.HIO_B_down_proj', 'model.layers.27.mlp.HSM_mask_proxy', 'model.layers.3.HIO_A_Attn', 'model.layers.3.HIO_A_MLP', 'model.layers.3.HIO_B_Attn', 'model.layers.3.HIO_B_MLP', 'model.layers.3.mlp.HIO_A_down_proj', 'model.layers.3.mlp.HIO_B_down_proj', 'model.layers.3.mlp.HSM_mask_proxy', 'model.layers.4.HIO_A_Attn', 'model.layers.4.HIO_A_MLP', 'model.layers.4.HIO_B_Attn', 'model.layers.4.HIO_B_MLP', 'model.layers.4.mlp.HIO_A_down_proj', 'model.layers.4.mlp.HIO_B_down_proj', 'model.layers.4.mlp.HSM_mask_proxy', 'model.layers.5.HIO_A_Attn', 'model.layers.5.HIO_A_MLP', 'model.layers.5.HIO_B_Attn', 'model.layers.5.HIO_B_MLP', 'model.layers.5.mlp.HIO_A_down_proj', 'model.layers.5.mlp.HIO_B_down_proj', 'model.layers.5.mlp.HSM_mask_proxy', 'model.layers.6.HIO_A_Attn', 'model.layers.6.HIO_A_MLP', 'model.layers.6.HIO_B_Attn', 'model.layers.6.HIO_B_MLP', 'model.layers.6.mlp.HIO_A_down_proj', 'model.layers.6.mlp.HIO_B_down_proj', 'model.layers.6.mlp.HSM_mask_proxy', 'model.layers.7.HIO_A_Attn', 'model.layers.7.HIO_A_MLP', 'model.layers.7.HIO_B_Attn', 'model.layers.7.HIO_B_MLP', 'model.layers.7.mlp.HIO_A_down_proj', 'model.layers.7.mlp.HIO_B_down_proj', 'model.layers.7.mlp.HSM_mask_proxy', 'model.layers.8.HIO_A_Attn', 'model.layers.8.HIO_A_MLP', 'model.layers.8.HIO_B_Attn', 'model.layers.8.HIO_B_MLP', 'model.layers.8.mlp.HIO_A_down_proj', 'model.layers.8.mlp.HIO_B_down_proj', 'model.layers.8.mlp.HSM_mask_proxy', 'model.layers.9.HIO_A_Attn', 'model.layers.9.HIO_A_MLP', 'model.layers.9.HIO_B_Attn', 'model.layers.9.HIO_B_MLP', 'model.layers.9.mlp.HIO_A_down_proj', 'model.layers.9.mlp.HIO_B_down_proj', 'model.layers.9.mlp.HSM_mask_proxy']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
08/16 11:52:57 - OpenCompass - INFO - Try to load the data from /data/kris/shared_data/datasets/NLP/opencompass/./data/lambada/test.jsonl
lambada_6 test 5153
08/16 11:52:57 - OpenCompass - INFO - Start inferencing [Llama-3.2-3B_hf/lambada_6]
[2025-08-16 11:52:57,731] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting build dataloader
[2025-08-16 11:52:57,731] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...
  0%|          | 0/41 [00:00<?, ?it/s]/home/kris/workspace/qianxuzhen/Pruning-LLMs/thirdparty/transformers-4.51.1/src/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/kris/workspace/qianxuzhen/Pruning-LLMs/thirdparty/transformers-4.51.1/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  2%|▏         | 1/41 [00:00<00:33,  1.18it/s]  5%|▍         | 2/41 [00:01<00:23,  1.65it/s]  7%|▋         | 3/41 [00:01<00:21,  1.79it/s] 10%|▉         | 4/41 [00:02<00:19,  1.90it/s] 12%|█▏        | 5/41 [00:02<00:17,  2.05it/s] 15%|█▍        | 6/41 [00:03<00:16,  2.12it/s] 17%|█▋        | 7/41 [00:03<00:15,  2.17it/s] 20%|█▉        | 8/41 [00:03<00:14,  2.22it/s] 22%|██▏       | 9/41 [00:04<00:14,  2.25it/s] 24%|██▍       | 10/41 [00:04<00:13,  2.29it/s] 27%|██▋       | 11/41 [00:05<00:12,  2.31it/s] 29%|██▉       | 12/41 [00:05<00:12,  2.25it/s] 32%|███▏      | 13/41 [00:06<00:12,  2.24it/s] 34%|███▍      | 14/41 [00:06<00:12,  2.25it/s] 37%|███▋      | 15/41 [00:07<00:11,  2.22it/s] 39%|███▉      | 16/41 [00:07<00:11,  2.25it/s] 41%|████▏     | 17/41 [00:07<00:10,  2.27it/s] 44%|████▍     | 18/41 [00:08<00:10,  2.24it/s] 46%|████▋     | 19/41 [00:08<00:09,  2.21it/s] 49%|████▉     | 20/41 [00:09<00:09,  2.24it/s] 51%|█████     | 21/41 [00:09<00:08,  2.23it/s] 54%|█████▎    | 22/41 [00:10<00:08,  2.24it/s] 56%|█████▌    | 23/41 [00:10<00:08,  2.23it/s] 59%|█████▊    | 24/41 [00:11<00:07,  2.22it/s] 61%|██████    | 25/41 [00:11<00:07,  2.21it/s] 63%|██████▎   | 26/41 [00:12<00:06,  2.20it/s] 66%|██████▌   | 27/41 [00:12<00:06,  2.23it/s] 68%|██████▊   | 28/41 [00:12<00:05,  2.25it/s] 71%|███████   | 29/41 [00:13<00:05,  2.24it/s] 73%|███████▎  | 30/41 [00:13<00:04,  2.23it/s] 76%|███████▌  | 31/41 [00:14<00:04,  2.23it/s] 78%|███████▊  | 32/41 [00:14<00:03,  2.26it/s] 80%|████████  | 33/41 [00:15<00:03,  2.27it/s] 83%|████████▎ | 34/41 [00:15<00:03,  2.28it/s] 85%|████████▌ | 35/41 [00:15<00:02,  2.28it/s] 88%|████████▊ | 36/41 [00:16<00:02,  2.24it/s] 90%|█████████ | 37/41 [00:16<00:01,  2.24it/s] 93%|█████████▎| 38/41 [00:17<00:01,  2.21it/s] 95%|█████████▌| 39/41 [00:17<00:00,  2.20it/s] 98%|█████████▊| 40/41 [00:18<00:00,  2.11it/s]100%|██████████| 41/41 [00:18<00:00,  2.21it/s]100%|██████████| 41/41 [00:18<00:00,  2.19it/s]
08/16 11:53:16 - OpenCompass - INFO - time elapsed: 26.14s
