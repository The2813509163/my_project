08/16 11:52:48 - OpenCompass - INFO - Task [Llama-3.2-3B_hf/lambada_7]
08/16 11:52:50 - OpenCompass - WARNING - pad_token_id is not set for the tokenizer.
08/16 11:52:50 - OpenCompass - WARNING - Using eos_token_id 128001 as pad_token_id.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  2.04it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.84it/s]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /data/kris/shared_data/models/Llama-3.2-3B and are newly initialized: ['model.HIO_A_Emb', 'model.HIO_B_Emb', 'model.HSM_mask_proxy', 'model.layers.0.HIO_A_Attn', 'model.layers.0.HIO_A_MLP', 'model.layers.0.HIO_B_Attn', 'model.layers.0.HIO_B_MLP', 'model.layers.0.mlp.HIO_A_down_proj', 'model.layers.0.mlp.HIO_B_down_proj', 'model.layers.0.mlp.HSM_mask_proxy', 'model.layers.1.HIO_A_Attn', 'model.layers.1.HIO_A_MLP', 'model.layers.1.HIO_B_Attn', 'model.layers.1.HIO_B_MLP', 'model.layers.1.mlp.HIO_A_down_proj', 'model.layers.1.mlp.HIO_B_down_proj', 'model.layers.1.mlp.HSM_mask_proxy', 'model.layers.10.HIO_A_Attn', 'model.layers.10.HIO_A_MLP', 'model.layers.10.HIO_B_Attn', 'model.layers.10.HIO_B_MLP', 'model.layers.10.mlp.HIO_A_down_proj', 'model.layers.10.mlp.HIO_B_down_proj', 'model.layers.10.mlp.HSM_mask_proxy', 'model.layers.11.HIO_A_Attn', 'model.layers.11.HIO_A_MLP', 'model.layers.11.HIO_B_Attn', 'model.layers.11.HIO_B_MLP', 'model.layers.11.mlp.HIO_A_down_proj', 'model.layers.11.mlp.HIO_B_down_proj', 'model.layers.11.mlp.HSM_mask_proxy', 'model.layers.12.HIO_A_Attn', 'model.layers.12.HIO_A_MLP', 'model.layers.12.HIO_B_Attn', 'model.layers.12.HIO_B_MLP', 'model.layers.12.mlp.HIO_A_down_proj', 'model.layers.12.mlp.HIO_B_down_proj', 'model.layers.12.mlp.HSM_mask_proxy', 'model.layers.13.HIO_A_Attn', 'model.layers.13.HIO_A_MLP', 'model.layers.13.HIO_B_Attn', 'model.layers.13.HIO_B_MLP', 'model.layers.13.mlp.HIO_A_down_proj', 'model.layers.13.mlp.HIO_B_down_proj', 'model.layers.13.mlp.HSM_mask_proxy', 'model.layers.14.HIO_A_Attn', 'model.layers.14.HIO_A_MLP', 'model.layers.14.HIO_B_Attn', 'model.layers.14.HIO_B_MLP', 'model.layers.14.mlp.HIO_A_down_proj', 'model.layers.14.mlp.HIO_B_down_proj', 'model.layers.14.mlp.HSM_mask_proxy', 'model.layers.15.HIO_A_Attn', 'model.layers.15.HIO_A_MLP', 'model.layers.15.HIO_B_Attn', 'model.layers.15.HIO_B_MLP', 'model.layers.15.mlp.HIO_A_down_proj', 'model.layers.15.mlp.HIO_B_down_proj', 'model.layers.15.mlp.HSM_mask_proxy', 'model.layers.16.HIO_A_Attn', 'model.layers.16.HIO_A_MLP', 'model.layers.16.HIO_B_Attn', 'model.layers.16.HIO_B_MLP', 'model.layers.16.mlp.HIO_A_down_proj', 'model.layers.16.mlp.HIO_B_down_proj', 'model.layers.16.mlp.HSM_mask_proxy', 'model.layers.17.HIO_A_Attn', 'model.layers.17.HIO_A_MLP', 'model.layers.17.HIO_B_Attn', 'model.layers.17.HIO_B_MLP', 'model.layers.17.mlp.HIO_A_down_proj', 'model.layers.17.mlp.HIO_B_down_proj', 'model.layers.17.mlp.HSM_mask_proxy', 'model.layers.18.HIO_A_Attn', 'model.layers.18.HIO_A_MLP', 'model.layers.18.HIO_B_Attn', 'model.layers.18.HIO_B_MLP', 'model.layers.18.mlp.HIO_A_down_proj', 'model.layers.18.mlp.HIO_B_down_proj', 'model.layers.18.mlp.HSM_mask_proxy', 'model.layers.19.HIO_A_Attn', 'model.layers.19.HIO_A_MLP', 'model.layers.19.HIO_B_Attn', 'model.layers.19.HIO_B_MLP', 'model.layers.19.mlp.HIO_A_down_proj', 'model.layers.19.mlp.HIO_B_down_proj', 'model.layers.19.mlp.HSM_mask_proxy', 'model.layers.2.HIO_A_Attn', 'model.layers.2.HIO_A_MLP', 'model.layers.2.HIO_B_Attn', 'model.layers.2.HIO_B_MLP', 'model.layers.2.mlp.HIO_A_down_proj', 'model.layers.2.mlp.HIO_B_down_proj', 'model.layers.2.mlp.HSM_mask_proxy', 'model.layers.20.HIO_A_Attn', 'model.layers.20.HIO_A_MLP', 'model.layers.20.HIO_B_Attn', 'model.layers.20.HIO_B_MLP', 'model.layers.20.mlp.HIO_A_down_proj', 'model.layers.20.mlp.HIO_B_down_proj', 'model.layers.20.mlp.HSM_mask_proxy', 'model.layers.21.HIO_A_Attn', 'model.layers.21.HIO_A_MLP', 'model.layers.21.HIO_B_Attn', 'model.layers.21.HIO_B_MLP', 'model.layers.21.mlp.HIO_A_down_proj', 'model.layers.21.mlp.HIO_B_down_proj', 'model.layers.21.mlp.HSM_mask_proxy', 'model.layers.22.HIO_A_Attn', 'model.layers.22.HIO_A_MLP', 'model.layers.22.HIO_B_Attn', 'model.layers.22.HIO_B_MLP', 'model.layers.22.mlp.HIO_A_down_proj', 'model.layers.22.mlp.HIO_B_down_proj', 'model.layers.22.mlp.HSM_mask_proxy', 'model.layers.23.HIO_A_Attn', 'model.layers.23.HIO_A_MLP', 'model.layers.23.HIO_B_Attn', 'model.layers.23.HIO_B_MLP', 'model.layers.23.mlp.HIO_A_down_proj', 'model.layers.23.mlp.HIO_B_down_proj', 'model.layers.23.mlp.HSM_mask_proxy', 'model.layers.24.HIO_A_Attn', 'model.layers.24.HIO_A_MLP', 'model.layers.24.HIO_B_Attn', 'model.layers.24.HIO_B_MLP', 'model.layers.24.mlp.HIO_A_down_proj', 'model.layers.24.mlp.HIO_B_down_proj', 'model.layers.24.mlp.HSM_mask_proxy', 'model.layers.25.HIO_A_Attn', 'model.layers.25.HIO_A_MLP', 'model.layers.25.HIO_B_Attn', 'model.layers.25.HIO_B_MLP', 'model.layers.25.mlp.HIO_A_down_proj', 'model.layers.25.mlp.HIO_B_down_proj', 'model.layers.25.mlp.HSM_mask_proxy', 'model.layers.26.HIO_A_Attn', 'model.layers.26.HIO_A_MLP', 'model.layers.26.HIO_B_Attn', 'model.layers.26.HIO_B_MLP', 'model.layers.26.mlp.HIO_A_down_proj', 'model.layers.26.mlp.HIO_B_down_proj', 'model.layers.26.mlp.HSM_mask_proxy', 'model.layers.27.HIO_A_Attn', 'model.layers.27.HIO_A_MLP', 'model.layers.27.HIO_B_Attn', 'model.layers.27.HIO_B_MLP', 'model.layers.27.mlp.HIO_A_down_proj', 'model.layers.27.mlp.HIO_B_down_proj', 'model.layers.27.mlp.HSM_mask_proxy', 'model.layers.3.HIO_A_Attn', 'model.layers.3.HIO_A_MLP', 'model.layers.3.HIO_B_Attn', 'model.layers.3.HIO_B_MLP', 'model.layers.3.mlp.HIO_A_down_proj', 'model.layers.3.mlp.HIO_B_down_proj', 'model.layers.3.mlp.HSM_mask_proxy', 'model.layers.4.HIO_A_Attn', 'model.layers.4.HIO_A_MLP', 'model.layers.4.HIO_B_Attn', 'model.layers.4.HIO_B_MLP', 'model.layers.4.mlp.HIO_A_down_proj', 'model.layers.4.mlp.HIO_B_down_proj', 'model.layers.4.mlp.HSM_mask_proxy', 'model.layers.5.HIO_A_Attn', 'model.layers.5.HIO_A_MLP', 'model.layers.5.HIO_B_Attn', 'model.layers.5.HIO_B_MLP', 'model.layers.5.mlp.HIO_A_down_proj', 'model.layers.5.mlp.HIO_B_down_proj', 'model.layers.5.mlp.HSM_mask_proxy', 'model.layers.6.HIO_A_Attn', 'model.layers.6.HIO_A_MLP', 'model.layers.6.HIO_B_Attn', 'model.layers.6.HIO_B_MLP', 'model.layers.6.mlp.HIO_A_down_proj', 'model.layers.6.mlp.HIO_B_down_proj', 'model.layers.6.mlp.HSM_mask_proxy', 'model.layers.7.HIO_A_Attn', 'model.layers.7.HIO_A_MLP', 'model.layers.7.HIO_B_Attn', 'model.layers.7.HIO_B_MLP', 'model.layers.7.mlp.HIO_A_down_proj', 'model.layers.7.mlp.HIO_B_down_proj', 'model.layers.7.mlp.HSM_mask_proxy', 'model.layers.8.HIO_A_Attn', 'model.layers.8.HIO_A_MLP', 'model.layers.8.HIO_B_Attn', 'model.layers.8.HIO_B_MLP', 'model.layers.8.mlp.HIO_A_down_proj', 'model.layers.8.mlp.HIO_B_down_proj', 'model.layers.8.mlp.HSM_mask_proxy', 'model.layers.9.HIO_A_Attn', 'model.layers.9.HIO_A_MLP', 'model.layers.9.HIO_B_Attn', 'model.layers.9.HIO_B_MLP', 'model.layers.9.mlp.HIO_A_down_proj', 'model.layers.9.mlp.HIO_B_down_proj', 'model.layers.9.mlp.HSM_mask_proxy']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
08/16 11:52:55 - OpenCompass - INFO - Try to load the data from /data/kris/shared_data/datasets/NLP/opencompass/./data/lambada/test.jsonl
lambada_7 test 5153
08/16 11:52:55 - OpenCompass - INFO - Start inferencing [Llama-3.2-3B_hf/lambada_7]
[2025-08-16 11:52:55,301] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting build dataloader
[2025-08-16 11:52:55,301] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...
  0%|          | 0/40 [00:00<?, ?it/s]/home/kris/workspace/qianxuzhen/Pruning-LLMs/thirdparty/transformers-4.51.1/src/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/kris/workspace/qianxuzhen/Pruning-LLMs/thirdparty/transformers-4.51.1/src/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
  2%|▎         | 1/40 [00:01<00:40,  1.05s/it]  5%|▌         | 2/40 [00:01<00:28,  1.36it/s]  8%|▊         | 3/40 [00:02<00:23,  1.59it/s] 10%|█         | 4/40 [00:02<00:19,  1.80it/s] 12%|█▎        | 5/40 [00:02<00:17,  1.97it/s] 15%|█▌        | 6/40 [00:03<00:16,  2.09it/s] 18%|█▊        | 7/40 [00:03<00:15,  2.17it/s] 20%|██        | 8/40 [00:04<00:14,  2.14it/s] 22%|██▎       | 9/40 [00:04<00:14,  2.16it/s] 25%|██▌       | 10/40 [00:05<00:14,  2.14it/s] 28%|██▊       | 11/40 [00:05<00:13,  2.21it/s] 30%|███       | 12/40 [00:06<00:12,  2.26it/s] 32%|███▎      | 13/40 [00:06<00:12,  2.22it/s] 35%|███▌      | 14/40 [00:06<00:11,  2.21it/s] 38%|███▊      | 15/40 [00:07<00:11,  2.19it/s] 40%|████      | 16/40 [00:07<00:10,  2.22it/s] 42%|████▎     | 17/40 [00:08<00:10,  2.24it/s] 45%|████▌     | 18/40 [00:08<00:09,  2.29it/s] 48%|████▊     | 19/40 [00:09<00:09,  2.22it/s] 50%|█████     | 20/40 [00:09<00:09,  2.22it/s] 52%|█████▎    | 21/40 [00:10<00:08,  2.23it/s] 55%|█████▌    | 22/40 [00:10<00:08,  2.22it/s] 57%|█████▊    | 23/40 [00:11<00:07,  2.18it/s] 60%|██████    | 24/40 [00:11<00:07,  2.19it/s] 62%|██████▎   | 25/40 [00:11<00:06,  2.21it/s] 65%|██████▌   | 26/40 [00:12<00:06,  2.20it/s] 68%|██████▊   | 27/40 [00:12<00:05,  2.23it/s] 70%|███████   | 28/40 [00:13<00:05,  2.25it/s] 72%|███████▎  | 29/40 [00:13<00:04,  2.23it/s] 75%|███████▌  | 30/40 [00:14<00:04,  2.23it/s] 78%|███████▊  | 31/40 [00:14<00:04,  2.25it/s] 80%|████████  | 32/40 [00:15<00:03,  2.26it/s] 82%|████████▎ | 33/40 [00:15<00:03,  2.27it/s] 85%|████████▌ | 34/40 [00:15<00:02,  2.29it/s] 88%|████████▊ | 35/40 [00:16<00:02,  2.20it/s] 90%|█████████ | 36/40 [00:16<00:01,  2.21it/s] 92%|█████████▎| 37/40 [00:17<00:01,  2.24it/s] 95%|█████████▌| 38/40 [00:17<00:00,  2.27it/s] 98%|█████████▊| 39/40 [00:18<00:00,  2.28it/s]100%|██████████| 40/40 [00:18<00:00,  2.30it/s]100%|██████████| 40/40 [00:18<00:00,  2.16it/s]
08/16 11:53:13 - OpenCompass - INFO - time elapsed: 25.82s
